{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notbook is used to demonstrate building classification models using tree-based classifiers. The full version of this code is available in `09_classification_model.ipynb`. The dataset used for this exercise is borrowed from [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file location and name\n",
    "infile = 'https://raw.githubusercontent.com/vishal-git/dapt-631/main/data/credit_default_model_data.csv'\n",
    "\n",
    "# target variable (column name)\n",
    "target = 'default payment next month'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \n",
    "X = \n",
    "\n",
    "X_train = \n",
    "X_test = \n",
    "X_valid =\n",
    "\n",
    "y_train = \n",
    "y_test = \n",
    "y_valid = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn classifiers\n",
    "#--\n",
    "\n",
    "# define classifiers\n",
    "logit = \n",
    "tree = \n",
    "forest = \n",
    "gboost = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = \n",
    "\n",
    "#--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the predicted probabilities (scores) for the train and test paritions for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_scores_train = \n",
    "logit_scores_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_scores_train = tree.predict_proba(X_train)[:, 1]\n",
    "tree_scores_test = tree.predict_proba(X_test)[:, 1]\n",
    "\n",
    "forest_scores_train = forest.predict_proba(X_train)[:, 1]\n",
    "forest_scores_test = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "gboost_scores_train = gboost.predict_proba(X_train)[:, 1]\n",
    "gboost_scores_test = gboost.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--\n",
    "\n",
    "# calculate the false positive and true positive rates\n",
    "logit_fpr_train, logit_tpr_train, _ = \n",
    "logit_fpr_test, logit_tpr_test, _ = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_fpr_train, tree_tpr_train, _ = roc_curve(y_train, tree_scores_train)\n",
    "tree_fpr_test, tree_tpr_test, _ = roc_curve(y_test, tree_scores_test)\n",
    "\n",
    "forest_fpr_train, forest_tpr_train, _ = roc_curve(y_train, forest_scores_train)\n",
    "forest_fpr_test, forest_tpr_test, _ = roc_curve(y_test, forest_scores_test)\n",
    "\n",
    "gboost_fpr_train, gboost_tpr_train, _ = roc_curve(y_train, gboost_scores_train)\n",
    "gboost_fpr_test, gboost_tpr_test, _ = roc_curve(y_test, gboost_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "plt.plot(logit_fpr_train, logit_tpr_train, color='royalblue', lw=2, alpha=0.3,\n",
    "         label=f'LR Train (AUC = {roc_auc_score(y_train, logit_scores_train):0.3f})')\n",
    "\n",
    "plt.plot(tree_fpr_train, tree_tpr_train, color='green', lw=2, alpha=0.4,\n",
    "         label=f'DT Train (AUC = {roc_auc_score(y_train, tree_scores_train):0.3f})')\n",
    "\n",
    "plt.plot(forest_fpr_train, forest_tpr_train, color='tomato', lw=2, alpha=0.4,\n",
    "         label=f'RF Train (AUC = {roc_auc_score(y_train, forest_scores_train):0.3f})')\n",
    "\n",
    "plt.plot(gboost_fpr_train, gboost_tpr_train, color='purple', lw=2, alpha=0.2,\n",
    "         label=f'GB Train (AUC = {roc_auc_score(y_train, gboost_scores_train):0.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate', fontsize = 14)\n",
    "plt.ylabel('True Positive Rate', fontsize = 14)\n",
    "plt.title('Default Risk Model: Trainig Accuracy', fontsize = 16)\n",
    "plt.legend(loc=\"lower right\", fontsize = 14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "plt.plot(logit_fpr_test, logit_tpr_test, color='royalblue', lw=2,\n",
    "         label=f'LR Test  (AUC = {roc_auc_score(y_test, logit_scores_test):0.3f})')\n",
    "\n",
    "plt.plot(tree_fpr_test, tree_tpr_test, color='green', lw=2,\n",
    "         label=f'DT Test  (AUC = {roc_auc_score(y_test, tree_scores_test):0.3f})')\n",
    "\n",
    "plt.plot(forest_fpr_test, forest_tpr_test, color='darkorange', lw=2,\n",
    "         label=f'RF Test  (AUC = {roc_auc_score(y_test, forest_scores_test):0.3f})')\n",
    "\n",
    "plt.plot(gboost_fpr_test, gboost_tpr_test, color='purple', lw=2,\n",
    "         label=f'GB Test  (AUC = {roc_auc_score(y_test, gboost_scores_test):0.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, alpha=.5)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('Default Risk Model', fontsize=16)\n",
    "plt.legend(loc=\"lower right\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't standardized the input features. Let's see what happens when we do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression *with Standardization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--\n",
    "\n",
    "# define a scaler\n",
    "X_scaler = \n",
    "\n",
    "# fit the model after stadardizing all variables\n",
    "logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model scores\n",
    "logit_scores_train = logit.predict_proba(X_scaler.transform(X_train.astype(float)))[:, 1]\n",
    "logit_scores_test = logit.predict_proba(X_scaler.transform(X_test.astype(float)))[:, 1]\n",
    "\n",
    "# calculate False Positive Rates and True Positive Rates\n",
    "logit_fpr_train, logit_tpr_train, _ = roc_curve(y_train, logit_scores_train)\n",
    "logit_fpr_test, logit_tpr_test, _ = roc_curve(y_test, logit_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "plt.plot(logit_fpr_test, logit_tpr_test, color='royalblue', lw=2,\n",
    "         label=f'LR Test  (AUC = {roc_auc_score(y_test, logit_scores_test):0.3f})')\n",
    "\n",
    "plt.plot(tree_fpr_test, tree_tpr_test, color='green', lw=2,\n",
    "         label=f'DT Test  (AUC = {roc_auc_score(y_test, tree_scores_test):0.3f})')\n",
    "\n",
    "plt.plot(forest_fpr_test, forest_tpr_test, color='darkorange', lw=2,\n",
    "         label=f'RF Test  (AUC = {roc_auc_score(y_test, forest_scores_test):0.3f})')\n",
    "\n",
    "plt.plot(gboost_fpr_test, gboost_tpr_test, color='purple', lw=2,\n",
    "         label=f'GB Test  (AUC = {roc_auc_score(y_test, gboost_scores_test):0.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, alpha=.5)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('Default Risk Model', fontsize=16)\n",
    "plt.legend(loc=\"lower right\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next session, we will work on optimizing the model hyper-parameters to try to improve their performance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
