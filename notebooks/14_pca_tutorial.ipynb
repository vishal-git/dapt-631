{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to perform PCA and extract top components for further analysis. The extracted components are used here to perform Logistic Regression, but you will see that it doesn't generate desired results. Instead of a marginal reduction in model performance, the AUC of the model drops significantly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='darkgrid');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = 'https://raw.githubusercontent.com/vishal-git/dapt-631/main/data/credit_default_model_data.csv'\n",
    "\n",
    "target = 'default payment next month'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(infile)\n",
    "\n",
    "y = df[target]\n",
    "X = df.drop(target, axis=1)\n",
    "del df\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[X['group'] == 'M'].drop('group', axis=1)[X.columns[:-1]]\n",
    "X_test = X[X['group'] == 'T'].drop('group', axis=1)[X.columns[:-1]]\n",
    "\n",
    "y_train = y[X['group'] == 'M']\n",
    "y_test = y[X['group'] == 'T']\n",
    "\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = \n",
    "\n",
    "# fit and transform the training data frame\n",
    "X_train_std = \n",
    "\n",
    "# transform the test data frame\n",
    "X_test_std = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Normalize data before or after split of training and testing data?](https://stackoverflow.com/questions/49444262/normalize-data-before-or-after-split-of-training-and-testing-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and get model scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(X_train_std, y_train)\n",
    "\n",
    "logit_scores_train = logit.predict_proba(X_train_std)[:, 1]\n",
    "logit_scores_test = logit.predict_proba(X_test_std)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_fpr_test, logit_tpr_test, _ = roc_curve(y_test, logit_scores_test)\n",
    "auc_logit = roc_auc_score(y_test, logit_scores_test)\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "plt.figure().set_size_inches(7, 7)\n",
    "\n",
    "plt.plot(logit_fpr_test, logit_tpr_test, color='royalblue', lw=2, linestyle = '-',\n",
    "         label=f'Test (AUC = {auc_logit:0.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate', fontsize = 14)\n",
    "plt.ylabel('True Positive Rate', fontsize = 14)\n",
    "plt.title('Default Risk Model: Logistic Regression', fontsize = 14)\n",
    "plt.legend(loc=\"lower right\", fontsize = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = len(X_train.columns)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.lineplot(x=, \n",
    "             y=, \n",
    "             linewidth=3, \n",
    "             color='tomato')\n",
    "\n",
    "plt.xlabel('Number of Components', fontsize = 14)\n",
    "plt.ylabel('Explained Variance', fontsize = 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very few principal compoents appear to explain most of the variance in the data. This is a red flag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to *standardize* the data before fitting PCA -- i.e., run PCA on standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_train_std)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.lineplot(x=range(n_cols), \n",
    "             y=, \n",
    "             linewidth=3, \n",
    "             color='tomato')\n",
    "\n",
    "plt.xlabel('Number of Components', fontsize = 14)\n",
    "plt.ylabel('Explained Variance', fontsize = 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cumulative Variance Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "sns.lineplot(x=range(n_cols), \n",
    "             y=,\n",
    "             linewidth=3, \n",
    "             color='tomato')\n",
    "\n",
    "plt.xlabel('Number of Components', fontsize = 14)\n",
    "plt.ylabel('Explained Variance', fontsize = 14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_)[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep the top 30 principal compoents. By doing so, we will retain 97% of the total variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_to_keep = 30\n",
    "\n",
    "pca = PCA(n_components=components_to_keep, random_state=314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_X_train = \n",
    "pca_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model using principal components\n",
    "pl_fit = logit.fit(pca_X_train, y_train)\n",
    "\n",
    "# calculate model scores (predicted probabilities)\n",
    "pl_scores_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_fpr_test, pl_tpr_test, _ = roc_curve(y_test, pl_scores_test)\n",
    "auc_pl = roc_auc_score(y_test, pl_scores_test)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "plt.plot(logit_fpr_test, logit_tpr_test, color='royalblue', lw=2, \n",
    "         label=f'Logistic (AUC = {auc_logit:0.3f})')\n",
    "\n",
    "plt.plot(pl_fpr_test, pl_tpr_test, color='tomato', lw=2,\n",
    "         label=f'PCA + Logistic (AUC = {auc_pl:0.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate', fontsize = 14)\n",
    "plt.ylabel('True Positive Rate', fontsize = 14)\n",
    "plt.title('Default Risk Model: Logit vs. PCA+Logit', fontsize = 16)\n",
    "plt.legend(loc=\"lower right\", fontsize = 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did the model performance got worse?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
