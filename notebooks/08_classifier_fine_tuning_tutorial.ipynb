{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a continuation of `09_classifier.ipynb`. We built some basic classification models using tree-based classifiers in that notebook. In this notebook, we will optimize the hyper-parameters of those models to try to improve their performance. The full version of this notebook is available in `11_classifier_fine_tuning.ipynb`. The dataset used for this exercise is borrowed from [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file location and name\n",
    "infile = 'https://raw.githubusercontent.com/vishal-git/dapt-631/main/data/credit_default_model_data.csv'\n",
    "\n",
    "# target variable (column name)\n",
    "target = 'default payment next month'\n",
    "\n",
    "sns.set(style='darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(infile)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[target]\n",
    "X = df.drop(target, axis=1)\n",
    "\n",
    "X_train = X[X['group'] == 'M'].drop('group', axis=1)\n",
    "X_test = X[X['group'] == 'T'].drop('group', axis=1)\n",
    "X_valid = X[X['group'] == 'V'].drop('group', axis=1)\n",
    "\n",
    "y_train = y[X['group'] == 'M']\n",
    "y_test = y[X['group'] == 'T']\n",
    "y_valid = y[X['group'] == 'V']\n",
    "\n",
    "print(len(X_train), len(X_test), len(X_valid))\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fine-tune hyper-parameters for decision (classification) tree now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all values we would like to test\n",
    "max_depths = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a decision tree model using each value of `max_depth`. Once all models are built, we will pick the best value for `max_depth` based on the model performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty arrays -- we will use these to store model performance values\n",
    "auc_train, auc_test = \n",
    "\n",
    "for d in max_depths:\n",
    "    #--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the model performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "plt.plot()\n",
    "plt.plot()\n",
    "\n",
    "plt.xticks(max_depths)\n",
    "plt.ylim([0.0, 1.0])\n",
    "\n",
    "plt.xlabel('Max Depth', fontsize=14)\n",
    "plt.ylabel('AUC', fontsize=14)\n",
    "plt.title('Default Risk Model: Decision Tree (Max Depth)', fontsize=16)\n",
    "plt.legend(loc='best', fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out where AUC on the test set maximizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loc = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_auc = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_max_depth = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "plt.plot()\n",
    "plt.plot()\n",
    "\n",
    "plt.plot([5, 5], [0, 1], color='gray', linewidth=1, linestyle='--')\n",
    "plt.text(5+.2, 0.4, f'Best AUC={best_auc:.2f} (max_depth={best_max_depth})', fontsize=14,\n",
    "         color='royalblue', weight='semibold')\n",
    "\n",
    "plt.xticks(max_depths)\n",
    "plt.ylim([0.0, 1.0])\n",
    "\n",
    "plt.xlabel('Max Depth', fontsize = 14)\n",
    "plt.ylabel('AUC', fontsize = 14)\n",
    "plt.title('Default Risk Model: Decision Tree (Max Depth)', fontsize = 16)\n",
    "plt.legend(loc='best', fontsize = 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum Samples in the leaf nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all values we would like to test\n",
    "min_smpl_leaf = [0.4, 0.3, 0.2, 0.1, 0.05, 0.02, 0.01, 0.001]\n",
    "\n",
    "# create empty arrays -- we will use these to store model performance values\n",
    "auc_train, auc_test = [], []\n",
    "\n",
    "for msl in min_smpl_leaf:\n",
    "    \n",
    "    #--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the best value for min_samples_leaf\n",
    "best_loc = [i for i, auc_test_value in enumerate(auc_test) if auc_test_value == max(auc_test)][0]\n",
    "best_auc = auc_test[best_loc]\n",
    "best_msl = min_smpl_leaf[best_loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model performances\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "plt.plot(min_smpl_leaf, auc_train, color='tomato', lw=2, label='Train')\n",
    "\n",
    "plt.plot(min_smpl_leaf, auc_test, color='royalblue', lw=2, label='Test')\n",
    "\n",
    "plt.plot([best_msl, best_msl], [0, 1], color='gray', linewidth=1, linestyle='--')\n",
    "plt.text(0.2, 0.7, f'Best AUC={best_auc:.2f} (min_smpl_leaf={best_msl})', fontsize=14,\n",
    "         color='royalblue', weight='semibold')\n",
    "\n",
    "plt.xticks(min_smpl_leaf)\n",
    "plt.xlim([max(min_smpl_leaf), min(min_smpl_leaf)])\n",
    "plt.xscale('log')\n",
    "plt.ylim([0.5, 1.0])\n",
    "\n",
    "plt.xlabel('Min Samples Leaf', fontsize=14)\n",
    "plt.ylabel('AUC', fontsize=14)\n",
    "plt.title('Default Risk Model: Decision Tree (Min Samples Leaf)', fontsize=16)\n",
    "plt.legend(loc='best', fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid-search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of testing (fine-tuning) one hyper-parameter at a time, we can use grid search to assess combination of hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=314)\n",
    "\n",
    "# create a list of all parameters we want to test\n",
    "param_grid = \n",
    "\n",
    "# define the gridsearch object\n",
    "tree_gs = \n",
    "\n",
    "# fit the model\n",
    "tree_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best set of hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_scores_train = tree_gs.predict_proba(X_train)[:, 1]\n",
    "tree_scores_test = tree_gs.predict_proba(X_test)[:, 1]\n",
    "\n",
    "tree_fpr_train, tree_tpr_train, _ = roc_curve(y_train, tree_scores_train)\n",
    "tree_fpr_test, tree_tpr_test, _ = roc_curve(y_test, tree_scores_test)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "plt.plot(tree_fpr_train, tree_tpr_train, color='green', lw=2, alpha = 0.4, linestyle = '-',\n",
    "         label=f'DT Train (AUC = {roc_auc_score(y_train, tree_scores_train):0.3f})')\n",
    "\n",
    "plt.plot(tree_fpr_test, tree_tpr_test, color='green', lw=2, linestyle = '-',\n",
    "         label=f'DT Test (AUC = {roc_auc_score(y_test, tree_scores_test):0.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate', fontsize = 14)\n",
    "plt.ylabel('True Positive Rate', fontsize = 14)\n",
    "plt.title('Default Risk Model: Decision Tree', fontsize = 16)\n",
    "plt.legend(loc='lower right', fontsize = 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insted of testing every combination of hyper-parameters, we can perform a random test which picks random combinations from the given set.\n",
    "\n",
    "We will perform a random-search to optimize the following hyperparameters for a Random Forest model.\n",
    "\n",
    "Number of trees in random forest: `n_estimators = [200, 300]`\n",
    "\n",
    "Maximum number of levels in tree: `max_depth = [3, 6]`\n",
    "\n",
    "Minimum percentage of samples required in the leaf nodes: `min_samples_leaf = [0.02, 0.05]`\n",
    "\n",
    "Whether to select sub-samples for training each tree: `bootstrap = [True, False]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=314)\n",
    "\n",
    "param_grid = \n",
    "\n",
    "forest_gs = \n",
    "\n",
    "forest_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_scores_train = forest_gs.predict_proba(X_train)[:, 1]\n",
    "forest_scores_test = forest_gs.predict_proba(X_test)[:, 1]\n",
    "\n",
    "forest_fpr_train, forest_tpr_train, _ = roc_curve(y_train, forest_scores_train)\n",
    "forest_fpr_test, forest_tpr_test, _ = roc_curve(y_test, forest_scores_test)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "plt.plot(forest_fpr_train, forest_tpr_train, color='darkorange', lw=2, alpha = 0.5, linestyle = '-',\n",
    "         label=f'RF Train (AUC = {roc_auc_score(y_train, forest_scores_train):0.3f})')\n",
    "\n",
    "plt.plot(forest_fpr_test, forest_tpr_test, color='darkorange', lw=2, linestyle = '-',\n",
    "         label=f'RF Test (AUC = {roc_auc_score(y_test, forest_scores_test):0.3f})')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate', fontsize = 14)\n",
    "plt.ylabel('True Positive Rate', fontsize = 14)\n",
    "plt.title('Default Risk Model: Random Forest', fontsize = 16)\n",
    "plt.legend(loc='lower right', fontsize = 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Once you find the best set of hyper-parameters, you can further refine them by performing another random search using a new set of hyper-parameters -- the new values (to be tested) can be chosen based on the results from the first random search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will perform a random-search to optimize the following hyperparameters for a *Gradient Boosting* model.\n",
    "\n",
    "Number of trees: `n_estimators = [100, 300, 500]`\n",
    "\n",
    "Learning rate: `learning_rate = [0.05, 0.1]`\n",
    "\n",
    "Maximum number of levels in tree: `max_depth = [3, 6]`\n",
    "\n",
    "Minimum percentage of samples required in the leaf nodes: `min_samples_leaf = [0.01, 0.02, 0.05]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a model\n",
    "gbm = \n",
    "\n",
    "# create a list of all parameters we want to test\n",
    "param_grid = \n",
    "\n",
    "# define the gridsearch object\n",
    "gbm_rs = \n",
    "\n",
    "# fit the model\n",
    "gbm_rs.fit(X_train, y_train)\n",
    "\n",
    "print ('Best GBM Parameters:', gbm_rs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model scores\n",
    "gbm_scores_train = \n",
    "gbm_scores_test = \n",
    "\n",
    "# ROC curve data\n",
    "gbm_fpr_train, gbm_tpr_train, _ = \n",
    "gbm_fpr_test, gbm_tpr_test, _ = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "plt.plot(gbm_fpr_train, gbm_tpr_train, color='purple', lw=2, alpha = 0.2, linestyle = '-',\n",
    "         label=f'GBM Train (AUC = {roc_auc_score(y_train, gbm_scores_train):0.3f})')\n",
    "\n",
    "plt.plot(gbm_fpr_test, gbm_tpr_test, color='purple', lw=2, linestyle = '-',\n",
    "         label=f'GBM Test (AUC = {roc_auc_score(y_test, gbm_scores_test):0.3f})')\n",
    "\n",
    ";"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
